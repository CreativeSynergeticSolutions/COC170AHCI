<!doctype html>
<html lang="en">
<head>
	<title>Motion Detection</title>
	<!-- http://www.webrtc.org/ -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
	<style>
		body 
		{
			
			background-color: #ccccff;
			
			overflow: hidden;
			text-align:center;
		
		}
		#blendCanvas{
			
			
		}
		
		#main{
			width:100%;
			display:block !important;
			text-align:center;
			
		}
		#item{
			overflow:auto;
			text-align:center;
		}
		.monitor{
			display: none; 
			width: 320px; 
			height: 240px;
		}
		.videoCanvas{
			z-index: 1; 
			position: absolute; 
			left:0px;
			top:0px;
		}
		.layer2{
			z-index: 2; 
			position: absolute; 
			left:0px; top:0px; 
			opacity:0.5;
		}
		.blendCanvas{
			display: none; 
			position: relative; 
			left: 320px;
			top: 240px; width: 320px; height: 240px;
		}
	
	</style>
</head>
<body>

<div id="main">
<video id="monitor" autoplay class="monitor"></video>


<div id="canvasLayers" >
<canvas id="videoCanvas" width="320" height="240" class="videoCanvas"></canvas>
<canvas id="layer2"     width="320" height="240" class="layer2"></canvas>
</div>
<canvas id="blendCanvas" class="blendCanvas"></canvas>
<br />
<div id="item">
	<h2><div id="product">Jacket </div>	</h2>
	<img id="image" src="image1.png" />
	<br />
		<h4><div id="price">£500</div>	</h4>
	<h4><div id="quantityLeft">Quantity Left: 100</div></h4>
</div>

</div>



<script src="RequestAnimationFrame.js">
//  Provides requestAnimationFrame in a cross browser way.
//  http://paulirish.com/2011/requestanimationframe-for-smart-animating/
</script>

<script>

var products={
	
	"image1.png":
	[
		"Slim Fit Suit",
		"Quantity: 30",
		"Price: £100"
	],
	"image2.png":
	[
		"Hooded Coat",
		"Quantity: 20",
		"Price: £70"
	],
	"image3.png":
	[
		"Faux Fur Trim Bomber Jacket",
		"Quantity: 10",
		"Price: £95"
	]
	
	
}

navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
window.URL = window.URL || window.webkitURL;

var camvideo = document.getElementById('monitor');

	if (!navigator.getUserMedia) 
	{
		document.getElementById('messageError').innerHTML = 
			'Sorry. <code>navigator.getUserMedia()</code> is not available.';
	}
	navigator.getUserMedia({video: true}, gotStream, noStream);

function gotStream(stream) 
{
	if (window.URL) 
	{   camvideo.src = window.URL.createObjectURL(stream);   } 
	else // Opera
	{   camvideo.src = stream;   }

	camvideo.onerror = function(e) 
	{   stream.stop();   };

	stream.onended = noStream;
}

function noStream(e) 
{
	var msg = 'No camera available.';
	if (e.code == 1) 
	{   msg = 'User denied access to use camera.';   }
	document.getElementById('errorMessage').textContent = msg;
}
</script>

<!-- The code below contains a loop to draw the contents of the video tag
	 onto the canvas tag, enabling us to do cool things with the image. -->
<!-- Based on http://www.adobe.com/devnet/html5/articles/javascript-motion-detection.html -->
<script>
// assign global variables to HTML elements
var video = document.getElementById( 'monitor' );
var videoCanvas = document.getElementById( 'videoCanvas' );
var videoContext = videoCanvas.getContext( '2d' );

var layer2Canvas = document.getElementById( 'layer2' );
var layer2Context = layer2Canvas.getContext( '2d' );

var blendCanvas  = document.getElementById( "blendCanvas" );
var blendContext = blendCanvas.getContext('2d');

var messageArea = document.getElementById( "messageArea" );

// these changes are permanent
var w1=videoCanvas.width;
var h1=videoCanvas.height;

videoContext.translate(w1, 0);
videoContext.scale(-1, 1);
		
// background color if no video present
videoContext.fillStyle = '#ffffff';
videoContext.fillRect( 0, 0, videoCanvas.width, videoCanvas.height );				

var buttons = [];

var button1 = new Image();

button1.src ="image3.png";
var buttonData1 = { name:"image3.png", image:button1, x:0, y:5, w:100, h:100 };
buttons.push( buttonData1 );

var button2 = new Image();
button2.src ="image2.png";
var buttonData2 = { name:"image2.png", image:button2, x:w1-200, y:5, w:100, h:100 };
buttons.push( buttonData2 );

var button3 = new Image();
button3.src ="image1.png";
var buttonData3 = { name:"image1.png", image:button3, x: w1- 100, y:5, w:100, h:100 };
buttons.push( buttonData3 );

// start the loop				
animate();

function animate() 
{
    requestAnimationFrame( animate );
	
	render();	
	blend();	
	checkAreas();
}

function render() 
{	
	if ( video.readyState === video.HAVE_ENOUGH_DATA ) 
	{
		// mirror video
		videoContext.drawImage( video, 0, 0, videoCanvas.width, videoCanvas.height );
		for ( var i = 0; i < buttons.length; i++ )
			layer2Context.drawImage( buttons[i].image, buttons[i].x, buttons[i].y, buttons[i].w, buttons[i].h );		
	}
}

var lastImageData;

function blend() 
{
	var width  = videoCanvas.width;
	var height = videoCanvas.height;
	// get current webcam image data
	var sourceData = videoContext.getImageData(0, 0, width, height);
	// create an image if the previous image doesn�t exist
	if (!lastImageData) lastImageData = videoContext.getImageData(0, 0, width, height);
	// create a ImageData instance to receive the blended result
	var blendedData = videoContext.createImageData(width, height);
	// blend the 2 images
	differenceAccuracy(blendedData.data, sourceData.data, lastImageData.data);
	// draw the result in a canvas
	blendContext.putImageData(blendedData, 0, 0);
	// store the current webcam image
	lastImageData = sourceData;
}
function differenceAccuracy(target, data1, data2) 
{
	if (data1.length != data2.length) return null;
	var i = 0;
	while (i < (data1.length * 0.25)) 
	{
		var average1 = (data1[3*i] + data1[3*i+1] + data1[3*i+2]) / 3;
		var average2 = (data2[3*i] + data2[3*i+1] + data2[3*i+2]) / 3;
		var diff = threshold(fastAbs(average1 - average2));
		target[3*i]   = diff;
		target[3*i+1] = diff;
		target[3*i+2] = diff;
		target[3*i+3] = 0xFF;
		++i;
	}
}
function fastAbs(value) 
{
	return (value ^ (value >> 31)) - (value >> 31);
}
function threshold(value) 
{
	return (value > 0x15) ? 0xFF : 0;
}

// check if white region from blend overlaps area of interest (e.g. triggers)
function checkAreas() 
{
	for (var b = 0; b < buttons.length; b++)
	{
		// get the pixels in a note area from the blended image
		var blendedData = blendContext.getImageData( buttons[b].x, buttons[b].y, buttons[b].w, buttons[b].h );
			
		// calculate the average lightness of the blended data
		var i = 0;
		var sum = 0;
		var countPixels = blendedData.data.length * 0.25;
		while (i < countPixels) 
		{
			sum += (blendedData.data[i*4] + blendedData.data[i*4+1] + blendedData.data[i*4+2]);
			++i;
		}
		// calculate an average between of the color values of the note area [0-255]
		var average = Math.round(sum / (3 * countPixels));
		if (average > 50) // more than 20% movement detected
		{
			document.getElementById("image").src=buttons[b].name;
			document.getElementById("product").innerHTML=products[buttons[b].name][0];
			document.getElementById("price").innerHTML=products[buttons[b].name][2];
			document.getElementById("quantityLeft").innerHTML=products[buttons[b].name][1];
		}
	}
}

</script>

</body>
</html>
